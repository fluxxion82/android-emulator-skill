#!/usr/bin/env python3
"""
Android Emulator/Device Log Monitoring and Analysis

Real-time log streaming from Android devices/emulators with intelligent filtering,
error detection, and token-efficient summarization.

Features:
- Real-time log streaming from devices/emulators
- Smart filtering by app package, tag, severity
- Error/warning classification and deduplication
- Duration-based or continuous follow mode
- Token-efficient summaries with full logs saved to file
- Integration with test_recorder and app_state_capture

Usage Examples:
    # Monitor app logs in real-time (follow mode)
    python scripts/log_monitor.py --app com.myapp --follow

    # Capture logs for specific duration
    python scripts/log_monitor.py --app com.myapp --duration 30s

    # Extract errors and warnings only
    python scripts/log_monitor.py --severity error,warning --duration 1m

    # Save logs to file
    python scripts/log_monitor.py --app com.myapp --duration 1m --output logs/

    # Verbose output with full log lines
    python scripts/log_monitor.py --app com.myapp --verbose
"""

import argparse
import json
import re
import signal
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

from common.device_utils import build_adb_command, get_device_serial


class LogMonitor:
    """Monitor and analyze Android device/emulator logs with intelligent filtering."""

    # Android logcat priority levels
    PRIORITY_MAP = {
        "V": "verbose",
        "D": "debug",
        "I": "info",
        "W": "warning",
        "E": "error",
        "F": "fatal",
    }

    def __init__(
        self,
        app_package: Optional[str] = None,
        device_serial: Optional[str] = None,
        severity_filter: Optional[list] = None,
    ):
        """
        Initialize log monitor.

        Args:
            app_package: Filter logs by app package name
            device_serial: Device serial (auto-detects if None)
            severity_filter: List of severities to include (error, warning, info, debug, verbose)
        """
        self.app_package = app_package
        self.device_serial = device_serial
        self.severity_filter = severity_filter or ["error", "warning", "info", "debug"]

        # Log storage
        self.log_lines = []
        self.errors = []
        self.warnings = []
        self.info_messages = []

        # Statistics
        self.error_count = 0
        self.warning_count = 0
        self.info_count = 0
        self.debug_count = 0
        self.verbose_count = 0
        self.total_lines = 0

        # Deduplication
        self.seen_messages = set()

        # Process control
        self.log_process = None
        self.interrupted = False

    def parse_time_duration(self, duration_str: str) -> float:
        """
        Parse duration string to seconds.

        Args:
            duration_str: Duration like "30s", "5m", "1h"

        Returns:
            Duration in seconds
        """
        match = re.match(r"(\d+)([smh])", duration_str.lower())
        if not match:
            raise ValueError(
                f"Invalid duration format: {duration_str}. Use format like '30s', '5m', '1h'"
            )

        value, unit = match.groups()
        value = int(value)

        if unit == "s":
            return value
        if unit == "m":
            return value * 60
        if unit == "h":
            return value * 3600

        return 0

    def parse_logcat_line(self, line: str) -> Optional[dict]:
        """
        Parse logcat line.

        Android logcat format: date time PID TID Priority Tag: Message
        Example: 12-11 18:30:45.123  1234  5678 E ActivityManager: Error message

        Args:
            line: Logcat line to parse

        Returns:
            Dict with parsed fields or None if invalid
        """
        # Match logcat format
        pattern = r"(\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(\d+)\s+(\d+)\s+([VDIWEF])\s+([^:]+):\s*(.*)"
        match = re.match(pattern, line)

        if not match:
            return None

        timestamp, pid, tid, priority, tag, message = match.groups()

        return {
            "timestamp": timestamp,
            "pid": pid,
            "tid": tid,
            "priority": priority,
            "severity": self.PRIORITY_MAP.get(priority, "unknown"),
            "tag": tag.strip(),
            "message": message.strip(),
            "raw": line,
        }

    def classify_log_line(self, parsed: dict) -> str:
        """
        Get severity from parsed log line.

        Args:
            parsed: Parsed log dict

        Returns:
            Severity level (error, warning, info, debug, verbose)
        """
        priority = parsed.get("priority", "I")

        if priority in ["E", "F"]:
            return "error"
        elif priority == "W":
            return "warning"
        elif priority == "I":
            return "info"
        elif priority == "D":
            return "debug"
        else:  # V
            return "verbose"

    def deduplicate_message(self, message: str, tag: str) -> bool:
        """
        Check if message is duplicate.

        Args:
            message: Log message
            tag: Log tag

        Returns:
            True if this is a new message, False if duplicate
        """
        # Create signature from tag and message (without timestamps/PIDs)
        signature = f"{tag}:{message}"
        signature = re.sub(r"\d+", "", signature)  # Remove numbers
        signature = re.sub(r"\s+", " ", signature).strip()

        if signature in self.seen_messages:
            return False

        self.seen_messages.add(signature)
        return True

    def process_log_line(self, line: str):
        """
        Process a single log line.

        Args:
            line: Log line to process
        """
        if not line.strip():
            return

        # Parse logcat format
        parsed = self.parse_logcat_line(line)
        if not parsed:
            # Store unparsed line as-is
            self.log_lines.append(line)
            self.total_lines += 1
            return

        self.total_lines += 1
        self.log_lines.append(parsed["raw"])

        # Classify severity
        severity = self.classify_log_line(parsed)

        # Skip if not in filter
        if severity not in self.severity_filter:
            return

        # Deduplicate (for errors and warnings)
        if severity in ["error", "warning"]:
            if not self.deduplicate_message(parsed["message"], parsed["tag"]):
                return

        # Store by severity
        if severity == "error":
            self.error_count += 1
            self.errors.append(f"[{parsed['tag']}] {parsed['message']}")
        elif severity == "warning":
            self.warning_count += 1
            self.warnings.append(f"[{parsed['tag']}] {parsed['message']}")
        elif severity == "info":
            self.info_count += 1
            if len(self.info_messages) < 20:  # Keep only recent info
                self.info_messages.append(f"[{parsed['tag']}] {parsed['message']}")
        elif severity == "debug":
            self.debug_count += 1
        else:  # verbose
            self.verbose_count += 1

    def stream_logs(
        self,
        follow: bool = False,
        duration: Optional[float] = None,
        clear_first: bool = False,
    ) -> bool:
        """
        Stream logs from device/emulator.

        Args:
            follow: Follow mode (continuous streaming)
            duration: Capture duration in seconds
            clear_first: Clear logcat buffer before streaming

        Returns:
            True if successful
        """
        # Clear logcat if requested
        if clear_first:
            clear_cmd = build_adb_command("logcat", self.device_serial, "-c")
            try:
                subprocess.run(clear_cmd, check=True, capture_output=True)
            except subprocess.CalledProcessError:
                pass  # Ignore clear errors

        # Build logcat command
        cmd = build_adb_command("logcat", self.device_serial)

        # Add format (time format with full timestamps)
        cmd.append("-v")
        cmd.append("time")

        # Add app package filter if specified
        if self.app_package:
            # Get app PID
            pid_cmd = build_adb_command(
                "shell", self.device_serial, "pidof", self.app_package
            )
            try:
                result = subprocess.run(pid_cmd, capture_output=True, text=True, check=True)
                pid = result.stdout.strip()
                if pid:
                    cmd.append(f"--pid={pid}")
            except subprocess.CalledProcessError:
                # App might not be running, continue without PID filter
                pass

        # Add severity filters
        if self.severity_filter:
            # Build priority filter string
            # logcat uses single letters: V D I W E F
            priority_letters = []
            for sev in self.severity_filter:
                if sev == "error":
                    priority_letters.extend(["E", "F"])
                elif sev == "warning":
                    priority_letters.append("W")
                elif sev == "info":
                    priority_letters.append("I")
                elif sev == "debug":
                    priority_letters.append("D")
                elif sev == "verbose":
                    priority_letters.append("V")

            # Use the minimum priority level (shows that level and above)
            # V < D < I < W < E < F
            priority_order = ["V", "D", "I", "W", "E", "F"]
            if priority_letters:
                min_priority = priority_order[
                    min(priority_order.index(p) for p in priority_letters)
                ]
                cmd.append("*:{}".format(min_priority))

        # Setup signal handler for graceful interruption
        def signal_handler(sig, frame):
            self.interrupted = True
            if self.log_process:
                self.log_process.terminate()

        signal.signal(signal.SIGINT, signal_handler)

        try:
            # Start log streaming process
            self.log_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,  # Line buffered
            )

            # Track start time for duration
            start_time = datetime.now()

            # Process log lines
            for line in iter(self.log_process.stdout.readline, ""):
                if not line:
                    break

                # Process the line
                self.process_log_line(line.rstrip())

                # Print in follow mode
                if follow:
                    parsed = self.parse_logcat_line(line.rstrip())
                    if parsed:
                        severity = self.classify_log_line(parsed)
                        if severity in self.severity_filter:
                            print(line.rstrip())

                # Check duration
                if duration and (datetime.now() - start_time).total_seconds() >= duration:
                    break

                # Check if interrupted
                if self.interrupted:
                    break

            # Wait for process to finish
            self.log_process.wait()
            return True

        except Exception as e:
            print(f"Error streaming logs: {e}", file=sys.stderr)
            return False

        finally:
            if self.log_process:
                self.log_process.terminate()

    def get_summary(self, verbose: bool = False) -> str:
        """
        Get log summary.

        Args:
            verbose: Include full log details

        Returns:
            Formatted summary string
        """
        lines = []

        # Header
        if self.app_package:
            lines.append(f"Logs for: {self.app_package}")
        else:
            lines.append("Logs for: All processes")

        # Statistics
        lines.append(f"Total lines: {self.total_lines}")
        lines.append(
            f"Errors: {self.error_count}, Warnings: {self.warning_count}, Info: {self.info_count}"
        )

        # Top issues
        if self.errors:
            lines.append(f"\nTop Errors ({len(self.errors)}):")
            for error in self.errors[:5]:  # Show first 5
                lines.append(f"  ❌ {error[:120]}")  # Truncate long lines

        if self.warnings:
            lines.append(f"\nTop Warnings ({len(self.warnings)}):")
            for warning in self.warnings[:5]:  # Show first 5
                lines.append(f"  ⚠️  {warning[:120]}")

        # Verbose output
        if verbose and self.log_lines:
            lines.append("\n=== Recent Log Lines ===")
            for line in self.log_lines[-50:]:  # Last 50 lines
                lines.append(line)

        return "\n".join(lines)

    def get_json_output(self) -> dict:
        """Get log results as JSON."""
        return {
            "app_package": self.app_package,
            "device_serial": self.device_serial,
            "statistics": {
                "total_lines": self.total_lines,
                "errors": self.error_count,
                "warnings": self.warning_count,
                "info": self.info_count,
                "debug": self.debug_count,
                "verbose": self.verbose_count,
            },
            "errors": self.errors[:20],  # Limit to 20
            "warnings": self.warnings[:20],
            "sample_logs": self.log_lines[-50:],  # Last 50 lines
        }

    def save_logs(self, output_dir: str) -> str:
        """
        Save logs to file.

        Args:
            output_dir: Directory to save logs

        Returns:
            Path to saved log file
        """
        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        app_name = self.app_package.split(".")[-1] if self.app_package else "device"
        log_file = output_path / f"{app_name}-{timestamp}.log"

        # Write all log lines
        with open(log_file, "w") as f:
            f.write("\n".join(self.log_lines))

        # Also save JSON summary
        json_file = output_path / f"{app_name}-{timestamp}-summary.json"
        with open(json_file, "w") as f:
            json.dump(self.get_json_output(), f, indent=2)

        return str(log_file)


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Monitor and analyze Android device/emulator logs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Monitor app in real-time
  python scripts/log_monitor.py --app com.myapp --follow

  # Capture logs for 30 seconds
  python scripts/log_monitor.py --app com.myapp --duration 30s

  # Show errors/warnings only
  python scripts/log_monitor.py --severity error,warning --duration 1m

  # Save logs to file
  python scripts/log_monitor.py --app com.myapp --duration 1m --output logs/

  # Clear logs first, then monitor
  python scripts/log_monitor.py --app com.myapp --clear --follow
        """,
    )

    # Filtering options
    parser.add_argument(
        "--app", dest="app_package", help="App package name to filter logs (e.g., com.myapp)"
    )
    parser.add_argument(
        "--serial", dest="device_serial", help="Device serial (uses default if not specified)"
    )
    parser.add_argument(
        "--severity", help="Comma-separated severity levels (error,warning,info,debug,verbose)"
    )

    # Time options
    time_group = parser.add_mutually_exclusive_group()
    time_group.add_argument(
        "--follow", action="store_true", help="Follow mode (continuous streaming)"
    )
    time_group.add_argument("--duration", help="Capture duration (e.g., 30s, 5m, 1h)")

    # Output options
    parser.add_argument("--output", help="Save logs to directory")
    parser.add_argument("--verbose", action="store_true", help="Show detailed output")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    parser.add_argument(
        "--clear", action="store_true", help="Clear logcat buffer before streaming"
    )

    args = parser.parse_args()

    # Parse severity filter
    severity_filter = None
    if args.severity:
        severity_filter = [s.strip().lower() for s in args.severity.split(",")]

    # Initialize monitor
    monitor = LogMonitor(
        app_package=args.app_package,
        device_serial=args.device_serial,
        severity_filter=severity_filter,
    )

    # Parse duration
    duration = None
    if args.duration:
        duration = monitor.parse_time_duration(args.duration)

    # Stream logs
    print("Monitoring logs...", file=sys.stderr)
    if args.app_package:
        print(f"App: {args.app_package}", file=sys.stderr)

    success = monitor.stream_logs(
        follow=args.follow, duration=duration, clear_first=args.clear
    )

    if not success:
        sys.exit(1)

    # Save logs if requested
    if args.output:
        log_file = monitor.save_logs(args.output)
        print(f"\nLogs saved to: {log_file}", file=sys.stderr)

    # Output results
    if not args.follow:  # Don't show summary in follow mode
        if args.json:
            print(json.dumps(monitor.get_json_output(), indent=2))
        else:
            print("\n" + monitor.get_summary(verbose=args.verbose))

    sys.exit(0)


if __name__ == "__main__":
    main()
